[model]
name = ""
plugged_dataset = "dataset_name" # Dataset used for training
plugged_layers = ["layer_name"] # Layers used in the model
plugged_training = "training_name" # Training configuration used
plugged_output = "output_name" # Output configuration (model's final output)

[datasets]

[dataset.dataset_name]
address = "/home/dev/datasets/exemple_1.bin" # Path to the dataset
samples = [ { "name" = "sample_name", "quantity" = 10 } ] # List of samples in the dataset

[layers]

[layers.layer_name]
activation = "Relu" # Activation function
num_nodes = 4 # Number of nodes in this layer

[trainings]

[training.training_name] 
gradient_descendent = "batch" # Gradient descent type (batch, stochastic, or mini_batch)
learning_rate = 0.001 # Learning rate
batch_size = 100 # Number of samples per batch
num_epochs = 100 # Total number of epochs


[outputs]

[outputs.output_name]
path = "/home/dev/outputs/output_name.h5" # Path where the output is saved
num_epoch_to_checkpoint = 20 # Save checkpoint every 20 epochs
checkpoint = true # Whether to save the checkpoint for each 20 epochs or only when finish the training
read_output_as_starter_checkpoint = true # Read the output as a starting checkpoint for further training

